{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from datetime import date\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import  TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#Scrapping the tweets - Create a list to append tweet data\n",
    "tweets_list = []\n",
    "maxTweets = 100\n",
    "\n",
    "#Using TwitterSearchScraper to scrape data and append tweets to list \n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper('ChatGPT').get_items()):\n",
    "    if i == maxTweets:\n",
    "        break\n",
    "    tweets_list.append([tweet.rawContent])\n",
    "\n",
    "#Creating a dataframe from the tweets list above\n",
    "\n",
    "tweets_to_df = pd.DataFrame(tweets_list, columns=[\"Tweets\"])\n",
    "\n",
    "tweets_to_df.head() #list first five tweets\n",
    "\n",
    "#clean the tweets with a function\n",
    "\n",
    "def cleanTweets(text):\n",
    "    text = re.sub('@[A-Za-z0-9_]+', '', text) #remove @mentions\n",
    "    text = re.sub('#', '', text) #removes hastag '#' symbol\n",
    "    text = re.sub('RT[\\s]+', '',text)\n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text)\n",
    "    text = re.sub('\\n',' ', text)\n",
    "    return text\n",
    "tweets_to_df['cleanedTweets'] = tweets_to_df['Tweets'].apply(cleanTweets) #apply cleanTweet function to the tweet\n",
    "tweets_to_df.head() #compares original theets with cleaned tweets\n",
    "\n",
    "#save results in .csv file\n",
    "tweets_to_df.to_csv('tweets_ChatGPT.csv') #write dataframe into csv file\n",
    "saveTweets = pd.read_csv('../Sentiment_Data/tweets_ChatGPT.csv', index_col=0) #read csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "107d7b120a5b68773a87d4067e673630b35702e55ebab3138143d08b1c4d7cbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
